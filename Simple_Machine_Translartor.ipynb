{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Machine Translartor",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPZawVwecpGwSX2Q/Gi5Rdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaveshsingh0206/Machine-Translator/blob/master/Simple_Machine_Translartor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDXnRFy0RUwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Kfbw4xsMiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB = 20000\n",
        "DIMENSIONS = 300\n",
        "LSTM_UNITS = 256\n",
        "NUM_SAMPLES = 20000 \n",
        "BATCH_SIZE = 128  \n",
        "EPOCHS = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZQGPOKcRhqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = 0\n",
        "input_sequences = []\n",
        "target_input_sequences = []\n",
        "target_target_sequences = []\n",
        "with open('fra.txt') as f:\n",
        "  for i,line in enumerate(f):\n",
        "    t+=1\n",
        "    if t>NUM_SAMPLES:\n",
        "      break\n",
        "    line = line.rstrip().split('\\t')\n",
        "    input_text = line[0]\n",
        "    target_input = '<sos> ' + line[1]\n",
        "    temp = line[1] + ' <eos>'\n",
        "    input_sequences.append(input_text)\n",
        "    target_input_sequences.append(target_input)\n",
        "    target_target_sequences.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep6MTJ7QTYiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AsZ41DkUH_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rnwlglqR0-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading file from Drive\n",
        "import pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSGnHqsxR7Rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kivdHKLtR-ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloaded = drive.CreateFile({'id':\"1CJCcOIF5-6ceTotmjnF2Lm7JgEMm4zvJ\"}) \n",
        "# downloaded.GetContentFile('glove.6B.300d.txt')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uucd1HISIYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2Vec = {}\n",
        "with open('glove.6B.300d.txt') as f:\n",
        "  for line in f:\n",
        "    line = line.split(' ')\n",
        "    word = line[0]\n",
        "    word2Vec[word] = line[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBXaT3nnShlv",
        "colab_type": "code",
        "outputId": "92ceb4f6-e827-45de-e580-2ba298be703e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snRrTO0USpu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-wM8jGqVWRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB)\n",
        "tokenizer_inputs.fit_on_texts(input_sequences)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPtRXU0VVm6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = target_input_sequences+target_target_sequences\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB)\n",
        "tokenizer_outputs.fit_on_texts(total)\n",
        "target_input_sequences = tokenizer_outputs.texts_to_sequences(target_input_sequences)\n",
        "target_target_sequences = tokenizer_outputs.texts_to_sequences(target_target_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-VkzjSLVwQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_vocab_list = tokenizer_inputs.word_index\n",
        "output_vocab_list = tokenizer_outputs.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_RyIdJrWtsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words_input = min(MAX_VOCAB, len(input_vocab_list)+1)\n",
        "num_words_output = min(MAX_VOCAB, len(output_vocab_list)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8qoG_ciXoYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_input_len = max(len(s) for s in input_sequences)\n",
        "max_target_len = max(len(j) for j in target_target_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_input_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjZ4P1xsiO_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_input_sequences = pad_sequences(target_input_sequences, maxlen=max_target_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLUZ2H6FYEao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_target_sequences = pad_sequences(target_target_sequences, maxlen=max_target_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOCh7dJCY0S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((num_words_input, DIMENSIONS))\n",
        "for word, i in input_vocab_list.items():\n",
        "  embedding_vector = word2Vec.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImrSrvTrY-lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now its time to create rocking stuff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW_7sY3ZZRc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_embedding = Embedding(num_words_input, DIMENSIONS, trainable = True, weights=[embedding_matrix])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WO-aTmIkyzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = Input(shape=(max_input_len,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvVWltd6k80s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = encoder_embedding(encoder_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ylj8zZ5lAc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = LSTM(LSTM_UNITS, return_state=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31R6X3Q9ljYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_outputs, h, c = lstm(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BvaVT-ElqRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input = Input(shape=(max_target_len,))\n",
        "decoder_embedding = Embedding(num_words_output, DIMENSIONS)\n",
        "decoder_x = decoder_embedding(decoder_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOO3KsIjmXiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_initial_state = [h,c]\n",
        "decoder_lstm = LSTM(LSTM_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_output, _, _ = decoder_lstm(decoder_x, initial_state=decoder_initial_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EzvWXG9m_GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_final_output = decoder_dense(decoder_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TezQEYZznj_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targets_one_hot = np.zeros((len(target_input_sequences), max_target_len, num_words_output))\n",
        "\n",
        "for i, d in enumerate(target_target_sequences):\n",
        "  for t, word in enumerate(d):\n",
        "    if word > 0:\n",
        "      targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7-b_Dspnk-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_input, decoder_input], decoder_final_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHaXTtJwnzub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wltETk7To747",
        "colab_type": "code",
        "outputId": "37f0cfbf-55b3-4618-a869-8f94ba2f2cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 13)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 6, 300)       1054500     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 13, 300)      2166000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 570368      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 13, 256), (N 570368      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 13, 7220)     1855540     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 6,216,776\n",
            "Trainable params: 6,216,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpd7pMlYqSGj",
        "colab_type": "code",
        "outputId": "cf7b2a68-98c7-424f-ccd5-e18cc8d18a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit([input_sequences, target_input_sequences], targets_one_hot, epochs=EPOCHS, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 2.0187 - accuracy: 0.0906\n",
            "Epoch 2/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 1.6636 - accuracy: 0.1106\n",
            "Epoch 3/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 1.4415 - accuracy: 0.1370\n",
            "Epoch 4/30\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 1.2657 - accuracy: 0.1607\n",
            "Epoch 5/30\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 1.1254 - accuracy: 0.1764\n",
            "Epoch 6/30\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 1.0098 - accuracy: 0.1888\n",
            "Epoch 7/30\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 0.9102 - accuracy: 0.1987\n",
            "Epoch 8/30\n",
            "20000/20000 [==============================] - 100s 5ms/step - loss: 0.8241 - accuracy: 0.2082\n",
            "Epoch 9/30\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 0.7468 - accuracy: 0.2169\n",
            "Epoch 10/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.6768 - accuracy: 0.2253\n",
            "Epoch 11/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.6123 - accuracy: 0.2341\n",
            "Epoch 12/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.5527 - accuracy: 0.2429\n",
            "Epoch 13/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.4979 - accuracy: 0.2518\n",
            "Epoch 14/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.4495 - accuracy: 0.2601\n",
            "Epoch 15/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.4051 - accuracy: 0.2675\n",
            "Epoch 16/30\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 0.3655 - accuracy: 0.2757\n",
            "Epoch 17/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.3303 - accuracy: 0.2828\n",
            "Epoch 18/30\n",
            "20000/20000 [==============================] - 104s 5ms/step - loss: 0.2988 - accuracy: 0.2886\n",
            "Epoch 19/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.2713 - accuracy: 0.2944\n",
            "Epoch 20/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.2478 - accuracy: 0.2985\n",
            "Epoch 21/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.2277 - accuracy: 0.3026\n",
            "Epoch 22/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.2104 - accuracy: 0.3053\n",
            "Epoch 23/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.1950 - accuracy: 0.3077\n",
            "Epoch 24/30\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 0.1819 - accuracy: 0.3096\n",
            "Epoch 25/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.1703 - accuracy: 0.3115\n",
            "Epoch 26/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.1603 - accuracy: 0.3130\n",
            "Epoch 27/30\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 0.1518 - accuracy: 0.3142\n",
            "Epoch 28/30\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 0.1443 - accuracy: 0.3153\n",
            "Epoch 29/30\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 0.1379 - accuracy: 0.3158\n",
            "Epoch 30/30\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 0.1320 - accuracy: 0.3170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7f66780358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIFSqzZ-sinM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save('translator.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb1w9eORtsHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('translator.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pedM4OgvEIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "model = keras.models.load_model('translator.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3q5b02kwg2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding_model = Model(encoder_input, decoder_initial_state)\n",
        "decoder_inputs_h = Input(shape=(LSTM_UNITS,))\n",
        "decoder_inputs_c = Input(shape=(LSTM_UNITS,))\n",
        "decorder_initial_states = [decoder_inputs_h, decoder_inputs_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A9TIOuxzTCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inpu = Input(shape=(1,))\n",
        "decorder_embedded = decoder_embedding(inpu)\n",
        "decoder_predict_output, hi, ci = decoder_lstm(decorder_embedded, initial_state=decorder_initial_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caf2zja3t0aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_states = [hi, ci]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNxwsxaYt96Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_outputs = decoder_dense(decoder_predict_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxvOL-i2oXoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model([inpu]+decorder_initial_states, [decoder_outputs]+ decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDhyxvS_0JSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2word_eng = {v:k for k, v in input_vocab_list.items()}\n",
        "idx2word_trans = {v:k for k, v in output_vocab_list.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfb51d0-ovvZ",
        "colab_type": "code",
        "outputId": "4c56cdac-7e27-44d1-e37d-e424ed762bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  states_value = encoding_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = output_vocab_list['sos']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = output_vocab_list['eos']\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_target_len):\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + states_value\n",
        "    )\n",
        "    # output_tokens, h = decoder_model.predict(\n",
        "    #     [target_seq] + states_value\n",
        "    # ) # gru\n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "    # states_value = [h] # gru\n",
        "\n",
        "  return ' '.join(output_sentence)\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "  # Do some test translations\n",
        "  input_text = [\"free service\"]\n",
        "  input_text = tokenizer_inputs.texts_to_sequences(input_text)\n",
        "  input_text = pad_sequences(input_text, max_input_len)\n",
        "\n",
        "  # i = np.random.choice(len(input_texts))\n",
        "  # input_seq = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_text)\n",
        "  print('-')\n",
        "  print('Input:', input_text)\n",
        "  print('Translation:', translation)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: [[  0   0   0   0   0 240]]\n",
            "Translation: c'est libre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1znDa6IpKts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vED_db37p7jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP3qQw8V1vP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}